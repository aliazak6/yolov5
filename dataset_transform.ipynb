{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder containing the images and the output folder\n",
    "input_folder = '../datasets/thermal/images/train2017/'\n",
    "output_folder_t = '../datasets/t-yolov5/images'\n",
    "output_folder_t2 = '../datasets/t2-yolov5/images'\n",
    "image_files = os.listdir(input_folder)\n",
    "    \n",
    "# Sort the image files\n",
    "#image_files.sort()\n",
    "\n",
    "# Iterate over each image file\n",
    "for i, image_file in enumerate(image_files):\n",
    "    if image_file.endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "        # Read the current image\n",
    "        current_image_path = os.path.join(input_folder, image_file)\n",
    "        current_image = cv2.resize(cv2.imread(current_image_path, cv2.IMREAD_GRAYSCALE),(640,640))\n",
    "        # Get the file names of the previous and next images\n",
    "        prev_image_file = image_files[i-1] if i > 0 else image_files[i]\n",
    "        next_image_file = image_files[i+1] if i < len(image_files)-1 else image_files[i]\n",
    "        # Read the previous and next images\n",
    "        prev_image = cv2.resize((cv2.imread(os.path.join(input_folder, prev_image_file), cv2.IMREAD_GRAYSCALE) if prev_image_file else None),(640,640))\n",
    "        next_image = cv2.resize((cv2.imread(os.path.join(input_folder, next_image_file), cv2.IMREAD_GRAYSCALE) if next_image_file else None),(640,640))\n",
    "        \n",
    "        first_channel = np.abs(prev_image-current_image)\n",
    "        second_channel= np.abs(next_image-current_image)\n",
    "\n",
    "        t_image = np.dstack([current_image,prev_image,next_image])\n",
    "        t2_image = np.dstack([first_channel,second_channel,np.zeros_like(first_channel)])\n",
    "        t2_image = np.concatenate([t_image,t2_image],axis=1)\n",
    "        # Save the transformed image\n",
    "        output_path_t = os.path.join(output_folder_t, image_file)\n",
    "        output_path_t2 = os.path.join(output_folder_t2, image_file)\n",
    "        cv2.imwrite(output_path_t, t_image)\n",
    "        cv2.imwrite(output_path_t2,t2_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m torch.distributed.run --nproc_per_node 4 train.py --img 640 --epochs 300 --data t-yolov5.yaml --weights yolov5x.pt --name t-yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m torch.distributed.run --nproc_per_node 4 train.py --img 640 --epochs 5 --weights \"\" --data t2-yolov5.yaml --cfg yolov5x-t2.yaml --name t2-yolov5 --t2_yolov5 True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
